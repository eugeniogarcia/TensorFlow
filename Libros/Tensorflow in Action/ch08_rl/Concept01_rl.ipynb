{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch `08`: Concept `01`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **states** are previous history of stock prices, current budget, and current number of shares of a stock.\n",
    "\n",
    "The **actions** are buy, sell, or hold (i.e. do nothing).\n",
    "\n",
    "The stock market data comes from the Yahoo Finance library, `pip install yahoo-finance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from yahoo_finance import Share\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an abstract class called `DecisionPolicy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clase padre que implementa una politica\n",
    "#No tiene construcctor, y es esencialmente virtual\n",
    "class DecisionPolicy:\n",
    "    #Implementa la politica para seleccionar una accion en funcion del estado\n",
    "    def select_action(self, current_state, step):\n",
    "        #Es el equivalente a virtual en C\n",
    "        pass\n",
    "\n",
    "    def update_q(self, state, action, reward, next_state):\n",
    "        #Es el equivalente a virtual en C\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's one way we could implement the decision policy, called a random decision policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDecisionPolicy(DecisionPolicy):\n",
    "    def __init__(self, actions):\n",
    "        #Crea una propiedad actions donde se guardaran las acciones posibles\n",
    "        self.actions = actions\n",
    "\n",
    "    #Elige una accion al azar\n",
    "    def select_action(self, current_state, step):\n",
    "        action = random.choice(self.actions)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a good baseline. Now let's use a smarter approach using a neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q es la utilidad\n",
    "#Determina cual es el valor a largo plazo\n",
    "#Q = Q + epsilon * (-Q + reward + gamma * maxQ')\n",
    "#si gamma es 0 lo que estamos diciendo es que la utilidad es la recompensa que obtenemos en un determinado\n",
    "#instante. Cuando mayor sea gamma, mas valor damos a mazimizar no la recopensa en un determinado momento, sino el valor a \n",
    "#largo plazo\n",
    "#\n",
    "#La red tiene como entrada el estado, y como salida la utilidad q que logramos con cada accion que tomamos\n",
    "#esto es, usando esta funcion no estamos basando la eleccion de una accion EN LA RECOMPENSA INMEDIATA, SINO EN \n",
    "#AQUELLO QUE AUMENTE Q, LA UTILIDAD, MÁS. El parametro gamma define cuan equivalente recompensa y q son\n",
    "class QLearningDecisionPolicy(DecisionPolicy):\n",
    "    #Constructor\n",
    "    def __init__(self, actions, input_dim):\n",
    "        #Q = reward + gamma * maxQ'\n",
    "        self.gamma = 0.3\n",
    "\n",
    "        #Epsilon es un valor que cuanto mas cercano a uno sea, mas probable se hace que se elija la accion en base\n",
    "        #a lo que diga nuestra RN. Si el valor es 1, siempre se usa la RN. Si .95, el 5% de las ocasiones eligiremos\n",
    "        #la accion al azar\n",
    "        self.epsilon = 0.95\n",
    "        \n",
    "        #Guarda las acciones posibles\n",
    "        self.actions = actions\n",
    "        \n",
    "        #Vamos a definir una red neuronal. La RN modelara la utilidad Q.\n",
    "        #Dado un estado, nos dira cual es la utilidad que podemos esperar para cada una de las acciones posibles\n",
    "        \n",
    "        #La red neuronal tendra como salida un vector con el valor de la funcion q para cada una de \n",
    "        #las acciones posibles. Esto es, con un estado de partida, la RN\n",
    "        #nos dira en cada salida cual es el valor de q tras tomar una determinada accion\n",
    "        output_dim = len(actions)\n",
    "        \n",
    "        #Salida desperada de la red neuronal. Q para cada accion\n",
    "        self.y = tf.placeholder(tf.float32, [output_dim])\n",
    "        \n",
    "        #Entrada a la red neuronal. Sera el vector que representa el estado\n",
    "        self.x = tf.placeholder(tf.float32, [None, input_dim])\n",
    "\n",
    "        #Capas intermedias - hidden\n",
    "        h1_dim = 20\n",
    "        #Parametros que podran aprenderse en la primera capa intermedia\n",
    "        W1 = tf.Variable(tf.random_normal([input_dim, h1_dim]))\n",
    "        b1 = tf.Variable(tf.constant(0.1, shape=[h1_dim]))\n",
    "        #Salida de la primera capa intermedia. Usa una activacion relu\n",
    "        h1 = tf.nn.relu(tf.matmul(self.x, W1) + b1)\n",
    "        \n",
    "        #Parametros que podran aprenderse en la segunda capa intermedia\n",
    "        W2 = tf.Variable(tf.random_normal([h1_dim, output_dim]))\n",
    "        b2 = tf.Variable(tf.constant(0.1, shape=[output_dim]))\n",
    "        \n",
    "        #Salida de la red neuronal. Usa una activacion relu\n",
    "        self.q = tf.nn.relu(tf.matmul(h1, W2) + b2)\n",
    "\n",
    "        #La funcion de error cuadratica\n",
    "        loss = tf.square(self.y - self.q)\n",
    "        \n",
    "        #Aprendizaje. Crea una propiedad en la que guardara el modelo de aprendizaje\n",
    "        self.train_op = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "        \n",
    "        #Session. Ademas las variables de la sesion se han inicializado\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #Define la policy\n",
    "    #La policy determina dado un estado, que accion debe tomarse\n",
    "    #\n",
    "    #     s -> a\n",
    "    #\n",
    "    #Se usa el parametro epsilon\n",
    "    #Step indica el paso que estamos simulando. Viene a ser el instante de tiempo\n",
    "    def select_action(self, current_state, step):\n",
    "        #EL threshold ira aumentando con cada paso, de modo que cuanto mayor sea el paso mas probable sera elegir\n",
    "        #la accion con la red neuronal. Al principio es mas probable que elijamos la accion al azar\n",
    "        threshold = min(self.epsilon, step / 1000.)\n",
    "        #Con este truco tratamos de paliar el overfitting\n",
    "        if random.random() < threshold:\n",
    "            #El criterio es simple, usar la accion que maximice la utilidad Q\n",
    "            #Utiliza la red neuronal para determinar la utilidad de cada accion\n",
    "            action_q_vals = self.sess.run(self.q, feed_dict={self.x: current_state})\n",
    "            #Elegimos la accion que de lugar a una utilidad, Q, maxima\n",
    "            action_idx = np.argmax(action_q_vals)  # TODO: replace w/ tensorflow's argmax\n",
    "            action = self.actions[action_idx]\n",
    "        else:\n",
    "            #\n",
    "            #Elige una accion al azar\n",
    "            action = self.actions[random.randint(0, len(self.actions) - 1)]\n",
    "        return action\n",
    "\n",
    "    #En este metodo lo que vamos a hacer es entrenar la RN. Este es el corazon del Reinforce Learning\n",
    "    #Hay un aprendizaje que no esta basado en un training data, pero en nuestra experiencia, lo que percibimos\n",
    "    #Lo que queremos es aprender a calcular la utilidad que podemos conseguir con una determinada accion \n",
    "    #cuando nuestro estado es uno dado\n",
    "    #PAra entrenar a la RN necesitamos definir un valor esperado. Lo definimos usando una funcion que \"entendemos\"\n",
    "    #modela la utilidad de forma correcta. En nuestro caso:\n",
    "    #Q = reward + gamma * maxQ'\n",
    "    #En un juego de ajedrez, por ejemplo, esta funcion modelaria cual es el valor de nuestra partida cuando tomamos\n",
    "    #una determinada accion. Necesitariamos \n",
    "    #1. Saber el valor en cada momento la posicion del tablero. En nuestro ejercio la posicion de nuestro tablero es\n",
    "    # el valor del portfolio, calculado como el budget -cash - mas el valor de las acciones que tenemos\n",
    "    #2. En cada simulacion lo que hariamos es ir haciendo en cada instante un movimiento, evaluar la posicion del tablero, \n",
    "    #entrenar la red, evaluar el siguiente movimiento, y asi hasta terminar la partida. Una simulacion seria una partida\n",
    "    #En nuestro ejemplo, en cada partida evaluamos como evolucionario nuestro portfolio cada dia si fueramos tomando \n",
    "    #determinadas acciones. Al final de la simulacion habriamos llegado al ultimo dia del periodo \n",
    "    #\n",
    "    # s + a -> q\n",
    "    #\n",
    "    def update_q(self, state, action, reward, next_state):\n",
    "        \n",
    "        #Dado el estado actual, utiliza la RN para obtener la Q que la red predice para cada accion\n",
    "        #No estamos entrenando la RN, estamos usando el kernel y bias actual para calcular la acción\n",
    "        action_q_vals = self.sess.run(self.q, feed_dict={self.x: state})\n",
    "        \n",
    "        #1. Calcula maxQ\n",
    "        #hace lo mismo que antes, pero usando el siguiente estado\n",
    "        next_action_q_vals = self.sess.run(self.q, feed_dict={self.x: next_state})\n",
    "        #Determina cual seria el valor maximo de Q en el siguiente estado\n",
    "        next_action_idx = np.argmax(next_action_q_vals)\n",
    "        \n",
    "        #Obtiene cual es la accion que acabamos de usar (entrada a esta funcion)\n",
    "        current_action_idx = self.actions.index(action)\n",
    "        \n",
    "        #2. Calcula cual sera el nuevo Q para (s,a,r,s') segun la formula Q = reward + gamma * maxQ'\n",
    "        action_q_vals[0, current_action_idx] = reward + self.gamma * next_action_q_vals[0, next_action_idx]\n",
    "        action_q_vals = np.squeeze(np.asarray(action_q_vals))\n",
    "\n",
    "        #3. Entrena la RN con el estado y el valor calculado de Q\n",
    "        #De esta forma, la RN aprende a calcular el valor de la Q definida como Q = reward + gamma * maxQ'\n",
    "        self.sess.run(self.train_op, feed_dict={self.x: state, self.y: action_q_vals})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to run a simulation of buying and selling stocks from a market:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Devuelve el valor total de nuestro portfolio. Esto es, la suma del cash mas el valor de las acciones\n",
    "# initial_budget, initial_num_stocks\n",
    "#el cash inicial, y el numero de acciones iniciales\n",
    "# prices\n",
    "# La evolucion del precio de la accion a lo largo del tiempo\n",
    "# hist\n",
    "# A la hora de tomar decisiones con nuestra politica, utilizaremos el precio de la accion en el pasado. hist\n",
    "#define cuantos periodos atras nos remontaremos. 1 significaria que tomamos decisiones con la politica usando\n",
    "#el precio de la accion en el dia anterior. 2, significaria que usamos el precio en los dos dias antereiores\n",
    "#\n",
    "#En la primera ejecucion de la simulacion, y en el primer paso, la politica determinara la accion usando unos pesos\n",
    "#que no se han entrenado en absoluto\n",
    "#A medida que ejecutamos simulaciones vamos entrenando esta RN, con lo que deberiamos ver que el valor de nuestro portofolio\n",
    "#deberia incrementarse\n",
    "def run_simulation(policy, initial_budget, initial_num_stocks, prices, hist, debug=False):\n",
    "    #El estado es una lista formada por hist precios de la accion, el presupuesto y el numero de acciones\n",
    "    #Presupuesto al inicio\n",
    "    budget = initial_budget\n",
    "    #Numero de acciones al inicio\n",
    "    num_stocks = initial_num_stocks\n",
    "    #precio de la accion al inicio\n",
    "    share_value = 0\n",
    "    \n",
    "    transitions = list()\n",
    "    #para cada uno de los instantes para los que tenemos precios, \n",
    "    #1. determinara el estado\n",
    "    #2. y con el estado cual es la accion a tomar\n",
    "    #3. Con la accion determina cual es la reward y el siguiente estado\n",
    "    #\n",
    "    for i in range(len(prices) - hist - 1):\n",
    "        if i % 1000 == 0:\n",
    "            print('progress {:.2f}%'.format(float(100*i) / (len(prices) - hist - 1)))\n",
    "        \n",
    "        #1. Determina cual es el estado actual. \n",
    "        #Sera un vector de hist + 2 dimensiones. \n",
    "        #Las dos ultimas dimensiones son el cash y el numero de acciones\n",
    "        #las primeras hist posiciones son el precio de la accion en los instantes x a x+hist\n",
    "        current_state = np.asmatrix(np.hstack((prices[i:i+hist], budget, num_stocks)))\n",
    "        \n",
    "        #El portfolio se define como el valor monetario: cash mas el valor de las acciones\n",
    "        #El reward de una determinada accion se define como el cambio de valor del portfolio\n",
    "        current_portfolio = budget + num_stocks * share_value\n",
    "        \n",
    "        #2. Con el estado, seleccionamos la accion\n",
    "        action = policy.select_action(current_state, i)\n",
    "        \n",
    "        #3. Calculamos el reward\n",
    "        share_value = float(prices[i + hist])\n",
    "        if action == 'Buy' and budget >= share_value:\n",
    "            budget -= share_value\n",
    "            num_stocks += 1\n",
    "        elif action == 'Sell' and num_stocks > 0:\n",
    "            budget += share_value\n",
    "            num_stocks -= 1\n",
    "        else:\n",
    "            action = 'Hold'\n",
    "        new_portfolio = budget + num_stocks * share_value\n",
    "        reward = new_portfolio - current_portfolio\n",
    "        \n",
    "        #3. y calculamos el siguiente estado. Notese que los precios de la accion corresponden a un instante mas tarde\n",
    "        next_state = np.asmatrix(np.hstack((prices[i+1:i+hist+1], budget, num_stocks)))\n",
    "        \n",
    "        #Guardamos en la lista de transicciones el: estado actual, la accion que hemos elegido, la recompensa que la accion\n",
    "        #genero, y el nuevo estado (s, a, r, s')\n",
    "        transitions.append((current_state, action, reward, next_state))\n",
    "        \n",
    "        #Llamamos a la funcion que adiestra la RN \n",
    "        policy.update_q(current_state, action, reward, next_state)\n",
    "\n",
    "    portfolio = budget + num_stocks * share_value\n",
    "    if debug:\n",
    "        print('${}\\t{} shares'.format(budget, num_stocks))\n",
    "    return portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to run simulations multiple times and average out the performances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulations(policy, budget, num_stocks, prices, hist):\n",
    "    #Numero de veces que lanzara la simulacion\n",
    "    #Cada simulacion viene a aplicar desde el primer dia hasta el ultimo la politica para ver cual es la Q que obtendriamos\n",
    "    #En este proceso entrenamos a nuestra RN para que aprenda a calcular la Q de una determinada accion\n",
    "    num_tries = 5\n",
    "    final_portfolios = list()\n",
    "    for i in range(num_tries):\n",
    "        print('Running simulation {}...'.format(i + 1))\n",
    "        #Obtiene el portfolio de la interaccion\n",
    "        final_portfolio = run_simulation(policy, budget, num_stocks, prices, hist)\n",
    "        final_portfolios.append(final_portfolio)\n",
    "        print('Final portfolio: ${}'.format(final_portfolio))\n",
    "    plt.title('Final Portfolio Value')\n",
    "    plt.xlabel('Simulation #')\n",
    "    plt.ylabel('Net worth')\n",
    "    plt.plot(final_portfolios)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the following function to use the Yahoo Finance library and obtain useful stockmarket data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices(share_symbol, start_date, end_date, cache_filename='stock_prices.npy'):\n",
    "    try:\n",
    "        #Carga el dataset desde el archivo. Si el archivo no existiera se lanza una exception...\n",
    "        stock_prices = np.load(cache_filename)\n",
    "    except IOError:\n",
    "        #... y procederemos a crear el archivo\n",
    "        #Obtiene precios usando la libreria...\n",
    "        share = Share(share_symbol)\n",
    "        #...recupera el historico de precios\n",
    "        stock_hist = share.get_historical(start_date, end_date)\n",
    "        #Crea una lista con el precio de apertura de la accion\n",
    "        stock_prices = [stock_price['Open'] for stock_price in stock_hist]\n",
    "        #...y escribe en el archivo la lista\n",
    "        np.save(cache_filename, stock_prices)\n",
    "    #Hace un cast a float de los elementos de la lista\n",
    "    return stock_prices.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who wants to deal with stock market data without looking a pretty plots? No one. So we need this out of law:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dibuja los precios\n",
    "def plot_prices(prices):\n",
    "    plt.title('Opening stock prices')\n",
    "    plt.xlabel('day')\n",
    "    plt.ylabel('price ($)')\n",
    "    plt.plot(prices)\n",
    "    #Guarda el grafico\n",
    "    plt.savefig('prices.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a reinforcement learning policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Eugenio\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Running simulation 1...\n",
      "progress 0.00%\n",
      "progress 16.55%\n",
      "progress 33.10%\n",
      "progress 49.64%\n",
      "progress 66.19%\n",
      "progress 82.74%\n",
      "progress 99.29%\n",
      "Final portfolio: $85243.69805100014\n",
      "Running simulation 2...\n",
      "progress 0.00%\n",
      "progress 16.55%\n",
      "progress 33.10%\n",
      "progress 49.64%\n",
      "progress 66.19%\n",
      "progress 82.74%\n",
      "progress 99.29%\n",
      "Final portfolio: $217634.22995700032\n",
      "Running simulation 3...\n",
      "progress 0.00%\n",
      "progress 16.55%\n"
     ]
    }
   ],
   "source": [
    "#Funcion de entrada al modulo\n",
    "if __name__ == '__main__':\n",
    "    #Obtiene la lista de precios para MFT entre las fechas indicadas\n",
    "    prices = get_prices('MSFT', '1992-07-22', '2016-07-22')\n",
    "    #Representa los precios de la accion\n",
    "    plot_prices(prices)\n",
    "    \n",
    "    #Definimos las acciones de nuestro modelo. Son tres\n",
    "    actions = ['Buy', 'Sell', 'Hold']\n",
    "    hist = 3\n",
    "    \n",
    "    #Este es el metodo en el que se eligen las acciones al azar\n",
    "    # policy = RandomDecisionPolicy(actions)\n",
    "    #En este metodo se eligen las acciones usando una RN. La dimension del vector de entrada para la red neuronal\n",
    "    #es cinco. Esto significa que sutilizan cinco estados para entrenar la RN en cual es la accion que debe tomarse\n",
    "    policy = QLearningDecisionPolicy(actions, hist + 2)\n",
    "    \n",
    "    budget = 100000.0\n",
    "    num_stocks = 0\n",
    "    run_simulations(policy, budget, num_stocks, prices, hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
