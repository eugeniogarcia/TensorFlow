{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_tvPdyfA-BL"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "0O_LFhwSBCjm"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWUmcKKjtwXL"
   },
   "source": [
    "# Hub with Keras\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/hub_with_keras\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/hub_with_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/hub_with_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "crU-iluJIEzw"
   },
   "source": [
    "[TensorFlow Hub](http://tensorflow.org/hub) is a way to share pretrained model components. See the [TensorFlow Module Hub](https://tfhub.dev/) for a searchable listing of pre-trained models.\n",
    "\n",
    "This tutorial demonstrates:\n",
    "\n",
    "1. How to use TensorFlow Hub with `tf.keras`.\n",
    "1. How to do image classification using TensorFlow Hub.\n",
    "1. How to do simple transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKFUvuEho9Th"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RVsYZLEpEWs"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSiOCtv_Rwi_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Using cached https://files.pythonhosted.org/packages/10/5c/6f3698513cf1cd730a5ea66aec665d213adf9de59b34f362f270e0bd126f/tensorflow_hub-0.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tensorflow_hub) (1.16.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tensorflow_hub) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tensorflow_hub) (3.7.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from protobuf>=3.4.0->tensorflow_hub) (41.0.1)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.4.0\n",
      "Collecting tf-nightly-gpu\n",
      "  Using cached https://files.pythonhosted.org/packages/16/75/a2e5af193c974d6d7ae23e3d8fb9590f74691ec79015cc24181ab5a21c00/tf_nightly_gpu-1.14.1.dev20190425-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tf-nightly-gpu) (0.2.2)\n",
      "Collecting google-pasta>=0.1.2 (from tf-nightly-gpu)\n",
      "  Using cached https://files.pythonhosted.org/packages/64/bb/f1bbc131d6294baa6085a222d29abadd012696b73dcbf8cf1bf56b9f082a/google_pasta-0.1.5-py3-none-any.whl\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tf-nightly-gpu) (3.7.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tf-nightly-gpu) (0.7.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tf-nightly-gpu) (0.7.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tf-nightly-gpu) (1.16.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tf-nightly-gpu) (1.20.1)\n",
      "Collecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/c6/e699c210a72660744a36e7f24b4a5a2bf798ce27d009a7f48050a620569f/tb_nightly-1.14.0a20190427-py3-none-any.whl (3.1MB)\n",
      "Collecting tf-estimator-nightly (from tf-nightly-gpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/31/45/121122e3675e3727b18d0fc56bb23a108da2e20af850c8ef9e7fb7e24421/tf_estimator_nightly-1.14.0.dev2019042701-py2.py3-none-any.whl (485kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tf-nightly-gpu) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tf-nightly-gpu) (0.33.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tf-nightly-gpu) (1.0.9)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tf-nightly-gpu) (1.0.7)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tf-nightly-gpu) (1.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tf-nightly-gpu) (1.11.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tf-nightly-gpu) (41.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu) (0.15.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu) (3.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\eugenio\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tf-nightly-gpu) (2.9.0)\n",
      "Installing collected packages: google-pasta, tb-nightly, tf-estimator-nightly, tf-nightly-gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Eugenio\\\\Anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\python\\\\_pywrap_tensorflow_internal.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow_hub\n",
    "!pip install tf-nightly-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGNpmn43C0O6"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module '_pywrap_tensorflow_internal' has no attribute 'TF_ListPhysicalDevices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cc9eb27242d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRTLD_LOCAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__git_version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mTF_ListPhysicalDevices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_ListPhysicalDevices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m \u001b[0mTF_ListPhysicalDevices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_ListPhysicalDevices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mTFE_NewContextOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '_pywrap_tensorflow_internal' has no attribute 'TF_ListPhysicalDevices'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-V4l8oN8Lw2q"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module '_pywrap_tensorflow_internal' has no attribute 'TF_ListPhysicalDevices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f3765ff86e01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabsl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRTLD_LOCAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__git_version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mTF_ListPhysicalDevices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_ListPhysicalDevices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m \u001b[0mTF_ListPhysicalDevices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_ListPhysicalDevices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mTFE_NewContextOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '_pywrap_tensorflow_internal' has no attribute 'TF_ListPhysicalDevices'"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4YuF5HvpM1W"
   },
   "source": [
    "## An ImageNet classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xEY_Ow5loN6q"
   },
   "source": [
    "### Download the classifier\n",
    "\n",
    "Use `hub.module` to load a mobilenet, and `tf.keras.layers.Lambda` to wrap it up as a keras layer.\n",
    "\n",
    "Any [tf2 compatible image classifier url from tfhub.dev](https://tfhub.dev/s?q=tf2&module-type=image-classification) will work here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "feiXojVXAbI9"
   },
   "outputs": [],
   "source": [
    "classifier_url =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_6bGjoPtzau"
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pwZXaoV0uXp2"
   },
   "source": [
    "### Run it on a single image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQItP1i55-di"
   },
   "source": [
    "Download a single image to try the model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w5wDjXNjuXGD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "\n",
    "grace_hopper = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\n",
    "grace_hopper = Image.open(grace_hopper).resize(IMAGE_SHAPE)\n",
    "grace_hopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEmmBnGbLxPp"
   },
   "outputs": [],
   "source": [
    "grace_hopper = np.array(grace_hopper)/255.0\n",
    "grace_hopper.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ic8OEEo2b73"
   },
   "source": [
    "Add a batch dimension, and pass the image to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMquyn29v8q3"
   },
   "outputs": [],
   "source": [
    "result = classifier.predict(grace_hopper[np.newaxis, ...])\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKzjqENF6jDF"
   },
   "source": [
    "The result is a 1001 element vector of logits, rating the probability of each class for the image.\n",
    "\n",
    "So the top class ID can be found with argmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgXb44vt6goJ"
   },
   "outputs": [],
   "source": [
    "predicted_class = np.argmax(result[0], axis=-1)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YrxLMajMoxkf"
   },
   "source": [
    "### Decode the predictions\n",
    "\n",
    "We have the predicted class ID,\n",
    "Fetch the `ImageNet` labels, and decode the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ij6SrDxcxzry"
   },
   "outputs": [],
   "source": [
    "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uzziRK3Z2VQo"
   },
   "outputs": [],
   "source": [
    "plt.imshow(grace_hopper)\n",
    "plt.axis('off')\n",
    "predicted_class_name = imagenet_labels[predicted_class]\n",
    "_ = plt.title(\"Prediction: \" + predicted_class_name.title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amfzqn1Oo7Om"
   },
   "source": [
    "## Simple transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-nIpVJ94xrw"
   },
   "source": [
    "Using TF Hub it is simple to retrain the top layer of the model to recognize the classes in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z93vvAdGxDMD"
   },
   "source": [
    "### Dataset\n",
    "\n",
    " For this example you will use the TensorFlow flowers dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DrIUV3V0xDL_"
   },
   "outputs": [],
   "source": [
    "data_root = tf.keras.utils.get_file(\n",
    "  'flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "   untar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jFHdp18ccah7"
   },
   "source": [
    "The simplest way to load this data into our model is using `tf.keras.preprocessing.image.ImageDataGenerator`,\n",
    "\n",
    "All of TensorFlow Hub's image modules expect float inputs in the `[0, 1]` range. Use the `ImageDataGenerator`'s `rescale` parameter to achieve this.\n",
    "\n",
    "The image size will be handled later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PwQ_wYDcii9"
   },
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "image_data = image_generator.flow_from_directory(str(data_root), target_size=IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0p7iDOhIcqY2"
   },
   "source": [
    "The resulting object is an iterator that returns `image_batch, label_batch` pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4lDPkn2cpWZ"
   },
   "outputs": [],
   "source": [
    "for image_batch, label_batch in image_data:\n",
    "  print(\"Image batch shape: \", image_batch.shape)\n",
    "  print(\"Labe batch shape: \", label_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gTN7M_GxDLx"
   },
   "source": [
    "### Run the classifier on a batch of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3fvrZR8xDLv"
   },
   "source": [
    "Now run the classifier on the image batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbyg6tcyxDLh"
   },
   "outputs": [],
   "source": [
    "result_batch = classifier.predict(image_batch)\n",
    "result_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kv7ZwuR4xDLc"
   },
   "outputs": [],
   "source": [
    "predicted_class_names = imagenet_labels[np.argmax(result_batch, axis=-1)]\n",
    "predicted_class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QmvSWg9nxDLa"
   },
   "source": [
    "Now check how these predictions line up with the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXTB22SpxDLP"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "  plt.subplot(6,5,n+1)\n",
    "  plt.imshow(image_batch[n])\n",
    "  plt.title(predicted_class_names[n])\n",
    "  plt.axis('off')\n",
    "_ = plt.suptitle(\"ImageNet predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FUa3YkvhxDLM"
   },
   "source": [
    "See the `LICENSE.txt` file for image attributions.\n",
    "\n",
    "The results are far from perfect, but reasonable considering that these are not the classes the model was trained for (except \"daisy\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JzV457OXreQP"
   },
   "source": [
    "### Download the headless model\n",
    "\n",
    "TensorFlow Hub also distributes models without the top classification layer. These can be used to easily do transfer learning.\n",
    "\n",
    "Any [image feature vector url from tfhub.dev](https://tfhub.dev/s?module-type=image-feature-vector&q=tf2) will work here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "4bw8Jf94DSnP"
   },
   "outputs": [],
   "source": [
    "feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgwmHugQF-PD"
   },
   "source": [
    "Create the module, and check the expected image size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wB030nezBwI"
   },
   "outputs": [],
   "source": [
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                         input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUY-5Eyzuzlu"
   },
   "source": [
    "The feature extractor returns a 1280-element vector for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Of7i-35F09ls"
   },
   "outputs": [],
   "source": [
    "feature_batch = feature_extractor_layer(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CtFmF7A5E4tk"
   },
   "source": [
    "Freeze the variables in the feature extractor layer, so that the training only modifies the new classifier layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jg5ar6rcE4H-"
   },
   "outputs": [],
   "source": [
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RPVeouTksO9q"
   },
   "source": [
    "### Attach a classification head\n",
    "\n",
    "Now wrap the hub layer in a `tf.keras.Sequential` model, and add a new classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGcY27fY1q3Q"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_extractor_layer,\n",
    "  layers.Dense(image_data.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9VkAz00HOJx"
   },
   "outputs": [],
   "source": [
    "predictions = model(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sB7sVGJ23vrY"
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHbXQqIquFxQ"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "Use compile to configure the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3n0Wb9ylKd8R"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58-BLV7dupJA"
   },
   "source": [
    "Now use the `.fit` method to train the model.\n",
    "\n",
    "To keep this example short train just 2 epochs. To visualize the training progress, use a custom callback to log the loss and accuracy of each batch individually, instead of the epoch average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZ54Gubac4Lu"
   },
   "outputs": [],
   "source": [
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.batch_losses = []\n",
    "    self.batch_acc = []\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    self.batch_losses.append(logs['loss'])\n",
    "    self.batch_acc.append(logs['acc'])\n",
    "    self.model.reset_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EyMDJxt2HdHr"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)\n",
    "\n",
    "batch_stats_callback = CollectBatchStats()\n",
    "\n",
    "history = model.fit(image_data, epochs=2,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    callbacks = [batch_stats_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kd0N272B9Q0b"
   },
   "source": [
    "Now after, even just a few training iterations, we can already see that the model is making progress on the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5RfS1QIIP-P"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(batch_stats_callback.batch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3uvX11avTiDg"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(batch_stats_callback.batch_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kb__ZN8uFn-D"
   },
   "source": [
    "### Check the predictions\n",
    "\n",
    "To redo the plot from before, first get the ordered list of class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JGbEf5l1I4jz"
   },
   "outputs": [],
   "source": [
    "class_names = sorted(image_data.class_indices.items(), key=lambda pair:pair[1])\n",
    "class_names = np.array([key.title() for key, value in class_names])\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Olg6MsNGJTL"
   },
   "source": [
    "Run the image batch through the model and convert the indices to class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCLVCpEjJ_VP"
   },
   "outputs": [],
   "source": [
    "predicted_batch = model.predict(image_batch)\n",
    "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
    "predicted_label_batch = class_names[predicted_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CkGbZxl9GZs-"
   },
   "source": [
    "Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpFQR1MPMtT1"
   },
   "outputs": [],
   "source": [
    "label_id = np.argmax(label_batch, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wC_AYRJU9NQe"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "  plt.subplot(6,5,n+1)\n",
    "  plt.imshow(image_batch[n])\n",
    "  color = \"green\" if predicted_id[n] == label_id[n] else \"red\"\n",
    "  plt.title(predicted_label_batch[n].title(), color=color)\n",
    "  plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRcJnAABr22x"
   },
   "source": [
    "## Export your model\n",
    "\n",
    "Now that you've trained the model, export it as a saved model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PLcqg-RmsLno"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "\n",
    "export_path = \"/tmp/saved_models/{}\".format(int(t))\n",
    "tf.keras.experimental.export_saved_model(model, export_path)\n",
    "\n",
    "export_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhQ9liIUsPsi"
   },
   "source": [
    "Now confirm that we can reload it, and it still gives the same results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nI5fvkAQvbS"
   },
   "outputs": [],
   "source": [
    "reloaded = tf.keras.experimental.load_from_saved_model(export_path, custom_objects={'KerasLayer':hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jor83-LqI8xW"
   },
   "outputs": [],
   "source": [
    "result_batch = model.predict(image_batch)\n",
    "reloaded_result_batch = reloaded.predict(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnZO14taYPH6"
   },
   "outputs": [],
   "source": [
    "abs(reloaded_result_batch - result_batch).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYZd4MNiV3Rc"
   },
   "source": [
    "This saved model can loaded for inference later, or converted to [TFLite](https://www.tensorflow.org/lite/convert/) or [TFjs](https://github.com/tensorflow/tfjs-converter).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "W_tvPdyfA-BL"
   ],
   "name": "Hub with Keras.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
